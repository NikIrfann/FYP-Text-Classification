{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# Combining data into a file\n",
    "files = ['Africa_TripCom.csv', 'China_TripCom.csv', 'France_TripCom.csv', 'Greece_TripCom.csv', 'Indonesia_TripCom.csv', 'Italy_TripCom.csv', \n",
    "         'Japan_TripCom.csv', 'Korea_TripCom.csv', 'Malaysia_TripCom.csv', 'NewZealand_TripCom.csv', 'Oceania_TripCom.csv', 'Portugal_TripCom.csv',\n",
    "        'SouthAmerica_TripCom.csv', 'Switzerland_TripCom.csv', 'Thailand_TripCom.csv' ]\n",
    "#\n",
    "combinedata = pd.concat([pd.read_csv(file) for file in files], ignore_index=True)\n",
    "combinedata.to_csv('data0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data0.csv\n",
    "## Adding New column which is Class and set to default value (None)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Place                                            Details  \\\n",
      "0         Signal Hill  Signal Hill is located on the side of Table Mo...   \n",
      "1  Alexandria Library  This futuristic disc-shaped building is a worl...   \n",
      "2     Pompey's Pillar  The Pompeii Column towers over the ruins of th...   \n",
      "\n",
      "          Class  \n",
      "0  None Related  \n",
      "1  None Related  \n",
      "2  None Related  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.read_csv('data0.csv')\n",
    "column_to_read = ['Place', 'Details']\n",
    "selected = data[column_to_read].copy()\n",
    "\n",
    "# Add a new column named 'New_Column' and fill it with None values\n",
    "selected['Class'] = 'None Related'\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(selected.head(3))\n",
    "\n",
    "selected.to_csv('data1.0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  data1.0.csv\n",
    "## Combine data1.0 and ScienceRelated\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                  Place  \\\n",
      "0            0.0            Signal Hill   \n",
      "1            1.0     Alexandria Library   \n",
      "2            2.0        Pompey's Pillar   \n",
      "3            3.0  Nairobi National Park   \n",
      "4            4.0         Giraffe Centre   \n",
      "...          ...                    ...   \n",
      "1136         NaN          PrecisionLife   \n",
      "1137         NaN        Sophia Genetics   \n",
      "1138         NaN              SpIntellx   \n",
      "1139         NaN                 Tempus   \n",
      "1140         NaN       Yemaachi Biotech   \n",
      "\n",
      "                                                Details          Class  \\\n",
      "0     Signal Hill is located on the side of Table Mo...   None Related   \n",
      "1     This futuristic disc-shaped building is a worl...   None Related   \n",
      "2     The Pompeii Column towers over the ruins of th...   None Related   \n",
      "3     Nairobi National Park is 8 kilometers south of...   None Related   \n",
      "4     The Giraffe Center is home to endangered Roths...   None Related   \n",
      "...                                                 ...            ...   \n",
      "1136  a precision medicine company with patented A.I...  bioinformatic   \n",
      "1137  Sophia Genetics is a data-driven medicine soft...  bioinformatic   \n",
      "1138  SpIntellx is a computational and systems patho...  bioinformatic   \n",
      "1139  technology company that is building the world'...  bioinformatic   \n",
      "1140  uses immunogenomics, bioinformatics and artifi...  bioinformatic   \n",
      "\n",
      "             COUNTRY  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "...              ...  \n",
      "1136  UNITED KINGDOM  \n",
      "1137     SWITZERLAND  \n",
      "1138   UNITED STATES  \n",
      "1139   UNITED STATES  \n",
      "1140           GHANA  \n",
      "\n",
      "[1141 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Combining data into a file\n",
    "files = ['data1.0.csv', 'ScienceRelated.csv']\n",
    "combinedata = pd.concat([pd.read_csv(file) for file in files], ignore_index=True)\n",
    "combinedata.to_csv('data1.1.csv', index=False)\n",
    "print(combinedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  data1.1.csv\n",
    "## Select Place, Details, Class column\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                  Place  \\\n",
      "0            0.0            Signal Hill   \n",
      "1            1.0     Alexandria Library   \n",
      "2            2.0        Pompey's Pillar   \n",
      "3            3.0  Nairobi National Park   \n",
      "4            4.0         Giraffe Centre   \n",
      "...          ...                    ...   \n",
      "1136         NaN          PrecisionLife   \n",
      "1137         NaN        Sophia Genetics   \n",
      "1138         NaN              SpIntellx   \n",
      "1139         NaN                 Tempus   \n",
      "1140         NaN       Yemaachi Biotech   \n",
      "\n",
      "                                                Details          Class  \\\n",
      "0     Signal Hill is located on the side of Table Mo...   None Related   \n",
      "1     This futuristic disc-shaped building is a worl...   None Related   \n",
      "2     The Pompeii Column towers over the ruins of th...   None Related   \n",
      "3     Nairobi National Park is 8 kilometers south of...   None Related   \n",
      "4     The Giraffe Center is home to endangered Roths...   None Related   \n",
      "...                                                 ...            ...   \n",
      "1136  a precision medicine company with patented A.I...  bioinformatic   \n",
      "1137  Sophia Genetics is a data-driven medicine soft...  bioinformatic   \n",
      "1138  SpIntellx is a computational and systems patho...  bioinformatic   \n",
      "1139  technology company that is building the world'...  bioinformatic   \n",
      "1140  uses immunogenomics, bioinformatics and artifi...  bioinformatic   \n",
      "\n",
      "             COUNTRY  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "...              ...  \n",
      "1136  UNITED KINGDOM  \n",
      "1137     SWITZERLAND  \n",
      "1138   UNITED STATES  \n",
      "1139   UNITED STATES  \n",
      "1140           GHANA  \n",
      "\n",
      "[1141 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data1.1.csv')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Place  \\\n",
      "0               Signal Hill   \n",
      "1        Alexandria Library   \n",
      "2           Pompey's Pillar   \n",
      "3     Nairobi National Park   \n",
      "4            Giraffe Centre   \n",
      "...                     ...   \n",
      "1136          PrecisionLife   \n",
      "1137        Sophia Genetics   \n",
      "1138              SpIntellx   \n",
      "1139                 Tempus   \n",
      "1140       Yemaachi Biotech   \n",
      "\n",
      "                                                Details          Class  \n",
      "0     Signal Hill is located on the side of Table Mo...   None Related  \n",
      "1     This futuristic disc-shaped building is a worl...   None Related  \n",
      "2     The Pompeii Column towers over the ruins of th...   None Related  \n",
      "3     Nairobi National Park is 8 kilometers south of...   None Related  \n",
      "4     The Giraffe Center is home to endangered Roths...   None Related  \n",
      "...                                                 ...            ...  \n",
      "1136  a precision medicine company with patented A.I...  bioinformatic  \n",
      "1137  Sophia Genetics is a data-driven medicine soft...  bioinformatic  \n",
      "1138  SpIntellx is a computational and systems patho...  bioinformatic  \n",
      "1139  technology company that is building the world'...  bioinformatic  \n",
      "1140  uses immunogenomics, bioinformatics and artifi...  bioinformatic  \n",
      "\n",
      "[1141 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "column_to_read = ['Place', 'Details', 'Class']\n",
    "selected = data[column_to_read].copy()\n",
    "selected.to_csv('data1.2.csv', index=False)\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data1.2.csv\n",
    "## After getting column place, details and class\n",
    "# Now removing places without details(NaN)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Details</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Signal Hill</td>\n",
       "      <td>Signal Hill is located on the side of Table Mo...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandria Library</td>\n",
       "      <td>This futuristic disc-shaped building is a worl...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place                                            Details  \\\n",
       "0         Signal Hill  Signal Hill is located on the side of Table Mo...   \n",
       "1  Alexandria Library  This futuristic disc-shaped building is a worl...   \n",
       "\n",
       "          Class  \n",
       "0  None Related  \n",
       "1  None Related  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data1.2.csv')\n",
    "data_cleaned = data.dropna(subset=['Details'])\n",
    "data_cleaned.to_csv('data1.3.csv')\n",
    "data_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data1.3.csv\n",
    "## Clean data using NLTK\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ASUS\n",
      "[nltk_data]     TUF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\ASUS\n",
      "[nltk_data]     TUF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                  Place  \\\n",
      "0              0            Signal Hill   \n",
      "1              1     Alexandria Library   \n",
      "2              2        Pompey's Pillar   \n",
      "3              3  Nairobi National Park   \n",
      "4              4         Giraffe Centre   \n",
      "...          ...                    ...   \n",
      "1128        1136          PrecisionLife   \n",
      "1129        1137        Sophia Genetics   \n",
      "1130        1138              SpIntellx   \n",
      "1131        1139                 Tempus   \n",
      "1132        1140       Yemaachi Biotech   \n",
      "\n",
      "                                                Details          Class  \\\n",
      "0     Signal Hill is located on the side of Table Mo...   None Related   \n",
      "1     This futuristic disc-shaped building is a worl...   None Related   \n",
      "2     The Pompeii Column towers over the ruins of th...   None Related   \n",
      "3     Nairobi National Park is 8 kilometers south of...   None Related   \n",
      "4     The Giraffe Center is home to endangered Roths...   None Related   \n",
      "...                                                 ...            ...   \n",
      "1128  a precision medicine company with patented A.I...  bioinformatic   \n",
      "1129  Sophia Genetics is a data-driven medicine soft...  bioinformatic   \n",
      "1130  SpIntellx is a computational and systems patho...  bioinformatic   \n",
      "1131  technology company that is building the world'...  bioinformatic   \n",
      "1132  uses immunogenomics, bioinformatics and artifi...  bioinformatic   \n",
      "\n",
      "                                        Cleaned_Details  \n",
      "0     signal hill located side table mountain named ...  \n",
      "1     futuristic building reading place seats reader...  \n",
      "2     pompeii column towers ruins temple serapeum re...  \n",
      "3     nairobi national park 8 kilometers south nairo...  \n",
      "4     giraffe center home endangered rothschild gira...  \n",
      "...                                                 ...  \n",
      "1128  precision medicine company patented deep seman...  \n",
      "1129  sophia genetics medicine software company head...  \n",
      "1130  spintellx computational systems pathology comp...  \n",
      "1131  technology company building world largest libr...  \n",
      "1132  uses immunogenomics bioinformatics artificial ...  \n",
      "\n",
      "[1133 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK resources (run only once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Read\n",
    "data = pd.read_csv('data1.3.csv')\n",
    "\n",
    "# Function for cleaning text data\n",
    "def clean_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Causing lots of word missing alphabet\n",
    "    # Stemming (optional)\n",
    "    # porter = PorterStemmer()\n",
    "    # tokens = [porter.stem(word) for word in tokens]\n",
    "\n",
    "    # Join the tokens back into a string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the 'Details' column\n",
    "data['Cleaned_Details'] = data['Details'].apply(clean_text)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data)\n",
    "\n",
    "data.to_csv('data1.4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data1.4.csv\n",
    "## Read Place and Cleaned_details()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Details</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Signal Hill</td>\n",
       "      <td>signal hill located side table mountain named ...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandria Library</td>\n",
       "      <td>futuristic building reading place seats reader...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pompey's Pillar</td>\n",
       "      <td>pompeii column towers ruins temple serapeum re...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place                                            Details  \\\n",
       "0         Signal Hill  signal hill located side table mountain named ...   \n",
       "1  Alexandria Library  futuristic building reading place seats reader...   \n",
       "2     Pompey's Pillar  pompeii column towers ruins temple serapeum re...   \n",
       "\n",
       "          Class  \n",
       "0  None Related  \n",
       "1  None Related  \n",
       "2  None Related  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data1.4.csv')\n",
    "column_to_read = ['Place', 'Cleaned_Details', 'Class']\n",
    "selected = data[column_to_read].copy()\n",
    "selected.rename(columns={'Cleaned_Details': \"Details\"}, inplace=True)\n",
    "selected.to_csv('data1.5.csv', index=False)\n",
    "selected.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data1.5.csv\n",
    "## Tokenize Details\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Place                                  Tokenized_Details  \\\n",
      "0         Signal Hill  [signal, hill, located, side, table, mountain,...   \n",
      "1  Alexandria Library  [futuristic, building, reading, place, seats, ...   \n",
      "2     Pompey's Pillar  [pompeii, column, towers, ruins, temple, serap...   \n",
      "\n",
      "          Class  \n",
      "0  None Related  \n",
      "1  None Related  \n",
      "2  None Related  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.read_csv('data1.5.csv')\n",
    "column_to_read = ['Place', 'Details', 'Class']\n",
    "selected = data[column_to_read].copy()\n",
    "\n",
    "# Tokenize the 'Details' column\n",
    "selected['Tokenized_Details'] = selected['Details'].apply(word_tokenize)\n",
    "\n",
    "# Display the DataFrame with tokenized details\n",
    "print(selected[['Place', 'Tokenized_Details','Class']].head(3))\n",
    "\n",
    "selected.to_csv('data1.6.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data1.6.csv\n",
    "## Read Place and Tokenized_details()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place</th>\n",
       "      <th>Details</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Signal Hill</td>\n",
       "      <td>['signal', 'hill', 'located', 'side', 'table',...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandria Library</td>\n",
       "      <td>['futuristic', 'building', 'reading', 'place',...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pompey's Pillar</td>\n",
       "      <td>['pompeii', 'column', 'towers', 'ruins', 'temp...</td>\n",
       "      <td>None Related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Place                                            Details  \\\n",
       "0         Signal Hill  ['signal', 'hill', 'located', 'side', 'table',...   \n",
       "1  Alexandria Library  ['futuristic', 'building', 'reading', 'place',...   \n",
       "2     Pompey's Pillar  ['pompeii', 'column', 'towers', 'ruins', 'temp...   \n",
       "\n",
       "          Class  \n",
       "0  None Related  \n",
       "1  None Related  \n",
       "2  None Related  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data1.6.csv')\n",
    "column_to_read = ['Place', 'Tokenized_Details', 'Class']\n",
    "selected = data[column_to_read].copy()\n",
    "selected.rename(columns={'Tokenized_Details': \"Details\"}, inplace=True)\n",
    "selected.to_csv('data1.7.csv', index=False)\n",
    "selected.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data1.7.csv\n",
    "## TF-IDF\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Place                                            Details  \\\n",
      "0         Signal Hill  ['signal', 'hill', 'located', 'side', 'table',...   \n",
      "1  Alexandria Library  ['futuristic', 'building', 'reading', 'place',...   \n",
      "2     Pompey's Pillar  ['pompeii', 'column', 'towers', 'ruins', 'temp...   \n",
      "\n",
      "          Class  007  0115  095   10       100  1000  1005  ...  zones  zoo  \\\n",
      "0  None Related  0.0   0.0  0.0  0.0  0.000000   0.0   0.0  ...    0.0  0.0   \n",
      "1  None Related  0.0   0.0  0.0  0.0  0.000000   0.0   0.0  ...    0.0  0.0   \n",
      "2  None Related  0.0   0.0  0.0  0.0  0.058711   0.0   0.0  ...    0.0  0.0   \n",
      "\n",
      "   zoological  zoom  zug  zun  zurich  zwingli  zyt  évora  \n",
      "0         0.0   0.0  0.0  0.0     0.0      0.0  0.0    0.0  \n",
      "1         0.0   0.0  0.0  0.0     0.0      0.0  0.0    0.0  \n",
      "2         0.0   0.0  0.0  0.0     0.0      0.0  0.0    0.0  \n",
      "\n",
      "[3 rows x 11728 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.read_csv('data1.7.csv')\n",
    "column_to_read = ['Place', 'Details', 'Class']  # Assuming 'Cleaned_Details' is the preprocessed text column\n",
    "#selected = data[column_to_read].copy()\n",
    "\n",
    "# Create a TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')  # You can customize stop words as needed\n",
    "\n",
    "# Fit and transform the 'Cleaned_Details' column\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(selected['Details'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the TF-IDF DataFrame with the original DataFrame\n",
    "result_df = pd.concat([selected, tfidf_df], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use result_df\n",
    "## Naive bayes\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Confusion Matrix:\n",
      "[[186   0   0   0   0]\n",
      " [  5   0   0   0   0]\n",
      " [  4   0   0   1   1]\n",
      " [ 10   0   0   5   0]\n",
      " [  4   0   0   0  11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " None Related       0.89      1.00      0.94       186\n",
      "    aerospace       0.00      0.00      0.00         5\n",
      "bioinformatic       0.00      0.00      0.00         6\n",
      "biotechnology       0.83      0.33      0.48        15\n",
      "      robotic       0.92      0.73      0.81        15\n",
      "\n",
      "     accuracy                           0.89       227\n",
      "    macro avg       0.53      0.41      0.45       227\n",
      " weighted avg       0.84      0.89      0.86       227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS TUF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ASUS TUF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ASUS TUF\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Sample DataFrame\n",
    "#column_to_read = ['Place', 'Details', 'Class']  # Assuming 'Label' is your target variable\n",
    "selected = result_df.copy()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(selected, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['Details'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['Details'])\n",
    "\n",
    "# Create and train a Naive Bayes classifier\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tfidf, train_data['Class'])\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = naive_bayes_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(test_data['Class'], predictions)\n",
    "conf_matrix = confusion_matrix(test_data['Class'], predictions)\n",
    "classification_rep = classification_report(test_data['Class'], predictions)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('\\nConfusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_rep)\n",
    "\n",
    "# Save the train model to a file\n",
    "joblib.dump(naive_bayes_classifier, 'model.h5')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved TF-IDF vectorizer\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "\n",
    "def class_det(Details):\n",
    "    input_data = [Details]\n",
    "    vectorized_input_data = loaded_vectorizer.transform(input_data)\n",
    "    predictions = naive_bayes_classifier.predict(vectorized_input_data)\n",
    "    print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bioinformatic']\n"
     ]
    }
   ],
   "source": [
    "class_det('biotechnology and data science company that combines biology with artificial intelligence for the discovery of drugs. Recursion takes microscopic images to build biological datasets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
